<html><head><title>Model Comparison Report</title><style>body { font-family: Arial, sans-serif; margin: 20px; line-height: 1.6; } table { border-collapse: collapse; width: 100%; margin-bottom: 20px; box-shadow: 0 2px 3px rgba(0,0,0,0.1); } th, td { padding: 10px 12px; text-align: left; border: 1px solid #ddd; } th { background-color: #f2f2f2; font-weight: bold; } tr:nth-child(even) { background-color: #f9f9f9; } .lda { background-color: #e6f3ff; } .bert { background-color: #ffe6e6; } h1 { color: #2c3e50; border-bottom: 2px solid #3498db; padding-bottom: 10px; } h2 { color: #34495e; border-bottom: 1px solid #bdc3c7; padding-bottom: 5px; margin-top: 30px; } h3 { color: #7f8c8d; margin-top: 20px; } img { max-width: 80%; height: auto; display: block; margin: 15px auto; border: 1px solid #ddd; padding: 5px; box-shadow: 0 2px 3px rgba(0,0,0,0.1); } .section { margin-bottom: 30px; background-color: #fff; padding: 20px; border-radius: 5px; box-shadow: 0 1px 2px rgba(0,0,0,0.05); } ul { padding-left: 20px; } li { margin-bottom: 8px; } a { color: #3498db; text-decoration: none; } a:hover { text-decoration: underline; } .code { background-color: #ecf0f1; padding: 2px 5px; border-radius: 3px; font-family: monospace; } .value-positive { color: #27ae60; } .value-negative { color: #c0392b; } .value-neutral { color: #7f8c8d; }</style></head><body><h1>Model Comparison Report: LDA vs BERTopic</h1><div class='section'><h2>Introduction</h2><p>This report compares the performance and results of two topic modeling approaches applied to the same dataset:</p><ul><li><strong>LDA (Latent Dirichlet Allocation):</strong> A traditional probabilistic topic modeling method focused on word co-occurrences.</li><li><strong>BERTopic:</strong> A modern approach leveraging transformer-based sentence embeddings and clustering techniques.</li></ul><p>The comparison focuses on user topic distributions, suspicious user detection, topic coherence (if available), and qualitative topic assessment.</p></div><div class='section'><h2>Model Configuration</h2><table><thead><tr><th>Parameter</th><th class='lda'>LDA Config</th><th class='bert'>BERTopic Config</th></tr></thead><tbody><tr><td>Combine Posts by Window</td><td class='lda'>True</td><td class='bert'>True</td></tr><tr><td>Language Model (BERTopic)</td><td class='lda'>N/A</td><td class='bert'>all-MiniLM-L6-v2</td></tr><tr><td>Lemmatization (LDA)</td><td class='lda'>True</td><td class='bert'>N/A</td></tr><tr><td>HDBSCAN Min Cluster Size (BERTopic)</td><td class='lda'>N/A</td><td class='bert'>5</td></tr><tr><td>Min Topic Size</td><td class='lda'>N/A</td><td class='bert'>5</td></tr><tr><td>UMAP Components (BERTopic)</td><td class='lda'>N/A</td><td class='bert'>5</td></tr><tr><td>UMAP Neighbors (BERTopic)</td><td class='lda'>N/A</td><td class='bert'>15</td></tr><tr><td>Number of Topics</td><td class='lda'>5</td><td class='bert'>5</td></tr><tr><td>Time Bin</td><td class='lda'>month</td><td class='bert'>month</td></tr></tbody></table></div><div class='section'><h2>Performance & Results Comparison</h2><h3>Topic Coherence</h3><p>Topic coherence measures the semantic interpretability of topics based on their top words. Higher scores are generally better. <i>(Note: Coherence calculation methods might differ between models.)</i></p><table><thead><tr><th>Model</th><th>Mean Coherence Score</th><th>Difference (BERTopic - LDA)</th><th>% Improvement vs LDA</th></tr></thead><tbody><tr><td class='lda'>LDA</td><td>0.3618</td><td rowspan='2'>0.1061</td><td rowspan='2'>29.31%</td></tr><tr><td class='bert'>BERTopic</td><td>0.4679</td></tr></tbody></table><img src='coherence_comparison.png' alt='Coherence Comparison Chart'><h3>User Topic Narrowness Correlation</h3><p>This section compares how similarly the two models assess user topic concentration (narrowness/diversity) using various metrics. High correlation suggests agreement between models.</p><table><thead><tr><th>Metric</th><th>Correlation (LDA vs BERTopic)</th><th>LDA Mean ± Std Dev</th><th>BERTopic Mean ± Std Dev</th><th>Mean Difference (BERTopic - LDA)</th></tr></thead><tbody><tr><td>Gini Coefficient</td><td>0.044</td><td class='lda'>0.672 ± 0.138</td><td class='bert'>0.818 ± 0.028</td><td>+0.146</td></tr><tr><td>Shannon Entropy</td><td>0.016</td><td class='lda'>1.517 ± 0.687</td><td class='bert'>0.441 ± 0.261</td><td>-1.076</td></tr><tr><td>Top1 Ratio</td><td>-0.047</td><td class='lda'>0.576 ± 0.223</td><td class='bert'>0.925 ± 0.082</td><td>+0.350</td></tr></tbody></table><img src='narrowness_metrics_comparison.png' alt='Narrowness Metrics Comparison Scatter Plots'><h3>Suspicious User Detection</h3><p>This compares the sets of users flagged as potentially anomalous (e.g., bots, spammers) by each model based on posting frequency, topic narrowness, and content duplication.</p><table><thead><tr><th>Metric</th><th>Value</th></tr></thead><tbody><tr><td>Total Suspicious Users (LDA)</td><td>438</td></tr><tr><td>Total Suspicious Users (BERTopic)</td><td>448</td></tr><tr><td>Users Flagged by Both (Overlap)</td><td>433</td></tr><tr><td>Overlap % of LDA Total</td><td>98.9%</td></tr><tr><td>Overlap % of BERTopic Total</td><td>96.7%</td></tr><tr><td>Users Flagged by LDA Only</td><td>5</td></tr><tr><td>Users Flagged by BERTopic Only</td><td>15</td></tr></tbody></table><img src='suspicious_users_overlap.png' alt='Suspicious Users Overlap Venn Diagram'><p>See <a href='suspicious_user_discrepancies.csv'>suspicious_user_discrepancies.csv</a> for users flagged by only one model.</p></div><div class='section'><h2>Topic Word & Similarity Analysis</h2><p>View the detailed side-by-side topic word lists and similarity analysis: <a href='topic_words_comparison.html'>Topic Words Comparison Report</a></p><h3>Most Similar Topic Pairs (Jaccard > 0.1)</h3><p>Top pairs of topics from LDA and BERTopic based on shared words (calculated using top 20 words per topic).</p><table><thead><tr><th>LDA Topic ID</th><th>BERTopic Topic ID</th><th>Similarity Score</th><th>Number Shared Words</th><th>Example Shared Words</th></tr></thead><tbody><tr><td class='lda'>4</td><td class='bert'>1</td><td>0.364</td><td>8</td><td>der, die, für, ist, merkel</td></tr><tr><td class='lda'>0</td><td class='bert'>0</td><td>0.154</td><td>4</td><td>clinton, hillary, obama, people</td></tr><tr><td class='lda'>5</td><td class='bert'>0</td><td>0.154</td><td>4</td><td>clinton, news, obama, politics</td></tr><tr><td class='lda'>6</td><td class='bert'>0</td><td>0.154</td><td>4</td><td>dont, hillary, obama, people</td></tr></tbody></table></div><div class='section'><h2>Conclusions & Observations</h2><ul><li>BERTopic produced significantly more coherent topics than LDA according to the calculated metric, suggesting better semantic interpretability with the embedding-based approach for this dataset.</li><li>Low or negative correlation in user topic narrowness; the models significantly disagree on user behavior concentration.</li><li>High agreement (% overlap > 60%) between models on suspicious user detection, suggesting a core set of anomalous users are identified consistently.</li><li>Overall, BERTopic appears to offer advantages in topic quality (coherence) for this specific dataset run, while narrowness agreement varies. BERTopic's embedding approach may capture nuances missed by LDA.</li></ul></div><div class='section' style='text-align: center; font-size: 0.9em; color: #7f8c8d;'><p><em>Report generated on 2025-04-29 18:49:44</em></p></div></body></html>